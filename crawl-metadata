#!/usr/bin/env python3

# Walk through the AWS Metadata at http://169.254.169.254/latest/
# and display all the items.

# Author:   Michael Ludvig @ AWS.NZ
# Homepage: https://aws.nz/aws-utils/crawl-metadata
# License:  BSD

import urllib.request

base_url = "http://169.254.169.254/latest/"

def fetch(base_url, item):
    url = base_url + item
    try:
        f = urllib.request.urlopen(url)
    except Exception as e:
        print("[" + item + "]")
        print("HTTP ERROR %d: %s" % (e.status, e.reason))
        print("")
        return

    if not url.endswith('/'):
        # We are a file - print the content
        print("[" + item + "]")
        print(f.read().strip().decode('utf-8'))
        print("")
        return
    else:
        # We are a "directory" - recurse down
        while True:
            line = f.readline()
            if not line:
                break
            line = line.strip().decode('utf-8')
            fetch(base_url, item + line)

if __name__ == "__main__":
    for directory in [ "meta-data/", "user-data", "dynamic/" ]:
        fetch(base_url, directory)
